import sys
import numpy as np
import pyzed.sl as sl
import cv2
import time
import math
centers_list = []
x_axes_list = []
y_axes_list = []
z_axes_list = []

accept_data_list = []
init_offset = None
isCollect = False

def init():
    global init_offset
    #init_offset = np.array([-0.06743418, 0.06810218, 0.00329000])
    init_offset = np.array([-0.06841773, 0.06819089, 0.00421293])


def rotationMatrixToEulerAngles(R):
    """
    R: 3x3 íšŒì „ í–‰ë ¬ (numpy ë°°ì—´)
    ë°˜í™˜ê°’: (roll, pitch, yaw) - ë¼ë””ì•ˆ ë‹¨ìœ„
    ìˆœì„œ: roll (Xì¶• íšŒì „), pitch (Yì¶• íšŒì „), yaw (Zì¶• íšŒì „)
    """

    sy = math.sqrt(R[0,0] * R[0,0] + R[1,0] * R[1,0])

    singular = sy < 1e-6  # íŠ¹ì´ì  (gimbal lock) ì—¬ë¶€ íŒë‹¨

    if not singular:
        roll = math.atan2(R[2,1], R[2,2])
        pitch = math.atan2(-R[2,0], sy)
        yaw = math.atan2(R[1,0], R[0,0])
    else:
        # íŠ¹ì´ì  ì²˜ë¦¬
        roll = math.atan2(-R[1,2], R[1,1])
        pitch = math.atan2(-R[2,0], sy)
        yaw = 0

    return roll, pitch, yaw


def compute_pose_from_corners(corner3d: np.ndarray):
    """
    corner3d: (4, 3) ndarray, ë§ˆì»¤ì˜ 3D ì½”ë„ˆ ì¢Œí‘œ (order: top-left, top-right, bottom-right, bottom-left)

    Returns:
        R: (3, 3) rotation matrix
        t: (3, 1) translation vector (ì¤‘ì‹¬ ì¢Œí‘œ)
    """
    # ë§ˆì»¤ ì¤‘ì‹¬ ê³„ì‚°
    center = np.mean(corner3d, axis=0)

    # xì¶• ë°©í–¥: top-right - top-left
    x_axis = corner3d[1] - corner3d[0]
    x_axis = x_axis / np.linalg.norm(x_axis)

    # yì¶• ë°©í–¥: bottom-left - top-left
    y_axis = corner3d[3] - corner3d[0]
    y_axis = y_axis / np.linalg.norm(y_axis)

    # zì¶•ì€ x, yì˜ ì™¸ì 
    z_axis = np.cross(x_axis, y_axis)
    z_axis = z_axis / np.linalg.norm(z_axis)

    # yì¶•ì„ ë‹¤ì‹œ ì •ê·œí™” (ì§êµ ë³´ì •)
    y_axis = np.cross(z_axis, x_axis)
    y_axis = y_axis / np.linalg.norm(y_axis)

    # íšŒì „ í–‰ë ¬ êµ¬ì„±
    R = np.vstack((x_axis, y_axis, z_axis)).T  # 3x3

    return R, center.reshape(3, 1)

def get_probe_tip_pos(offset: np.ndarray, probe_center: np.ndarray, R: np.ndarray) -> np.ndarray:
    """
    ë§ˆì»¤ì˜ ìì„¸(R, t)ì™€ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ëœ ì˜¤í”„ì…‹ì„ ì‚¬ìš©í•˜ì—¬ í”„ë¡œë¸Œ íŒì˜ ì›”ë“œ ì¢Œí‘œë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.

    Args:
        offset (np.ndarray): í”„ë¡œë¸Œ íŒì˜ ë¡œì»¬ ì˜¤í”„ì…‹ ë²¡í„° (3,)
        probe_center (np.ndarray): ë§ˆì»¤ ì¤‘ì‹¬ì˜ ì›”ë“œ ì¢Œí‘œ t (3,)
        R (np.ndarray): ë§ˆì»¤ì˜ íšŒì „ í–‰ë ¬ (3, 3)

    Returns:
        np.ndarray: í”„ë¡œë¸Œ íŒì˜ ìµœì¢… ì›”ë“œ ì¢Œí‘œ (3,)
    """
    # R @ offset: ë¡œì»¬ ì˜¤í”„ì…‹ì„ ì›”ë“œ ì¢Œí‘œê³„ì˜ ë°©í–¥ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    # probe_center + ...: ì›”ë“œ ì¢Œí‘œê³„ì˜ ë§ˆì»¤ ì¤‘ì‹¬ì— ë³€í™˜ëœ ì˜¤í”„ì…‹ì„ ë”í•©ë‹ˆë‹¤.
    tip_position_world = probe_center + (R @ offset)
    
    return tip_position_world



# Probe Calibration
def calculate_optimal_offset(prove_centers, x_axes, y_axes, z_axes):
    global accept_data_list
    global init_offset
    """
    C++ì˜ CalProveOffset í•¨ìˆ˜ë¥¼ Pythonìœ¼ë¡œ ë³€í™˜í•œ í•¨ìˆ˜ì…ë‹ˆë‹¤.
    ì—¬ëŸ¬ ì¸¡ì • ìì„¸ì—ì„œ ê³„ì‚°ëœ ì›”ë“œ ì¢Œí‘œë“¤ì˜ í¸ì°¨ë¥¼ ìµœì†Œí™”í•˜ëŠ” ìµœì ì˜ 3D ì˜¤í”„ì…‹ì„ ì°¾ìŠµë‹ˆë‹¤.

    Args:
        prove_centers (np.ndarray): (N, 3) í˜•íƒœ. ê° ì¸¡ì • ìì„¸ì—ì„œì˜ ë§ˆì»¤ ì¤‘ì‹¬ ì¢Œí‘œë“¤.
        x_axes (np.ndarray): (N, 3) í˜•íƒœ. ê° ì¸¡ì • ìì„¸ì—ì„œì˜ ë¡œì»¬ Xì¶• ë²¡í„°ë“¤.
        y_axes (np.ndarray): (N, 3) í˜•íƒœ. ê° ì¸¡ì • ìì„¸ì—ì„œì˜ ë¡œì»¬ Yì¶• ë²¡í„°ë“¤.
        z_axes (np.ndarray): (N, 3) í˜•íƒœ. ê° ì¸¡ì • ìì„¸ì—ì„œì˜ ë¡œì»¬ Zì¶• ë²¡í„°ë“¤.
        
    Returns:
        tuple: (ìµœì  ì˜¤í”„ì…‹(np.ndarray), ìµœì†Œ ì˜¤ì°¨(float))
    """
    # 1. ì•Œê³ ë¦¬ì¦˜ íŒŒë¼ë¯¸í„° ì´ˆê¸°í™”
    step_num = 10       # ì´ ë°˜ë³µ íšŸìˆ˜
    side_num = 10       # ê° ì°¨ì›ì˜ ê·¸ë¦¬ë“œ ë¶„í•  ìˆ˜
    step_rate = 0.5     # íƒìƒ‰ ë²”ìœ„ ì¶•ì†Œ ë¹„ìœ¨
    step_size = 0.3     # ì´ˆê¸° íƒìƒ‰ ë²”ìœ„ (ë‹¨ìœ„: meter)
    #step_size = 300
    # ì‹œì‘ì  (ì´ˆê¸° ì¶”ì • ì˜¤í”„ì…‹)
    # C++ ì½”ë“œì˜ ê°’ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš© (ë‹¨ìœ„: meter)
    #current_pos = np.array([-0.096295, 0.096295, 0.003867])
    # ì‹¤ì œ ì¸¡ì • ê¸¸ì´
    #current_pos = np.array([-0.067006, 0.067650, 0.003617])
    # 1ì°¨ ìº˜ë¦¬ë¸Œë ˆì´ì…˜
    #current_pos = np.array([-0.0667, 0.0692, 0.0016])
    # 2ì°¨ ìº˜ë¦¬ë¸Œë ˆì´ì…˜
    #current_pos = np.array([-0.06845775, 0.06829175, 0.00501300])
    # 3ì°¨ ìº˜ë¦¬ë¸Œë ˆì´ì…˜
    #current_pos = np.array([-0.06771506, 0.06812835, 0.00385960])
    # 4ì°¨ ìº˜ë¦¬ë¸Œë ˆì´ì…˜
    #current_pos = np.array([-0.06743418, 0.06810218, 0.00329000])
    total_grid_points = side_num ** 3
    num_proves = len(prove_centers)
    
    print("ğŸš€ ìµœì  ì˜¤í”„ì…‹ íƒìƒ‰ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    accept_offset_list = []
    accept_error_list = []
    # 2. ìˆœì°¨ ëŒ€ì…ë²• ê¸°ë°˜ì˜ ë°˜ë³µ ìµœì í™” ë£¨í”„
    for s in range(step_num):
        # í˜„ì¬ íƒìƒ‰ ê³µê°„(ì •ìœ¡ë©´ì²´)ì˜ ì‹œì‘ì ê³¼ ê·¸ë¦¬ë“œ ê°„ê²© ê³„ì‚°
        start_point = init_offset - step_size / 2.0
        grid_step = step_size / side_num
        
        # ê° ê·¸ë¦¬ë“œ í¬ì¸íŠ¸ì˜ ì¢Œí‘œì™€ ì˜¤ì°¨ë¥¼ ì €ì¥í•  ë°°ì—´
        grid_positions = np.zeros((total_grid_points, 3))
        grid_errors = np.zeros(total_grid_points)
        
        # 3. 10x10x10 ê·¸ë¦¬ë“œ íƒìƒ‰
        for x in range(side_num):
            for y in range(side_num):
                for z in range(side_num):
                    idx = x + y * side_num + z * side_num * side_num
                    
                    # í˜„ì¬ ê·¸ë¦¬ë“œ í¬ì¸íŠ¸ì˜ ì˜¤í”„ì…‹ í›„ë³´ ê³„ì‚°
                    local_offset = start_point + np.array([x, y, z]) * grid_step
                    grid_positions[idx] = local_offset
                    
                    # 4. ì˜¤ì°¨ ê³„ì‚°
                    # ì´ ì˜¤í”„ì…‹ì„ ëª¨ë“  ì¸¡ì • ë°ì´í„°ì— ì ìš©í•˜ì—¬ ì›”ë“œ ì¢Œí‘œë“¤ì„ ê³„ì‚°
                    world_positions = np.zeros((num_proves, 3))
                    for i in range(num_proves):
                        world_positions[i] = prove_centers[i] + \
                                             x_axes[i] * local_offset[0] + \
                                             y_axes[i] * local_offset[1] + \
                                             z_axes[i] * local_offset[2]
                    
                    # ê³„ì‚°ëœ ì›”ë“œ ì¢Œí‘œë“¤ì˜ ì¤‘ì‹¬ì (centroid)ì„ êµ¬í•¨
                    centroid = np.mean(world_positions, axis=0)
                    
                    # ê° ì›”ë“œ ì¢Œí‘œì™€ ì¤‘ì‹¬ì  ì‚¬ì´ì˜ í‰ê·  ê±°ë¦¬ë¥¼ ì˜¤ì°¨ë¡œ ì •ì˜
                    distances = np.linalg.norm(world_positions - centroid, axis=1)
                    error = np.mean(distances)
                    grid_errors[idx] = error

        # 5. í˜„ì¬ ê·¸ë¦¬ë“œì—ì„œ ì˜¤ì°¨ê°€ ê°€ì¥ ì‘ì€ ì§€ì  ì°¾ê¸°
        min_idx = np.argmin(grid_errors)
        min_error = grid_errors[min_idx]
        best_pos_in_grid = grid_positions[min_idx]
        
        # 6. ë‹¤ìŒ ë°˜ë³µì„ ìœ„í•´ ì¤‘ì‹¬ì ê³¼ íƒìƒ‰ ë²”ìœ„ ì—…ë°ì´íŠ¸
        current_pos = best_pos_in_grid
        step_size *= step_rate
        
        # ì§„í–‰ ìƒí™© ì¶œë ¥ (mm ë‹¨ìœ„ë¡œ ë³€í™˜)
        pos_mm = current_pos  #* 1000
        error_mm = min_error * 1000
        print(f"[{s+1}/{step_num}] ì˜¤í”„ì…‹: ({pos_mm[0]:.6f}, {pos_mm[1]:.6f}, {pos_mm[2]:.6f}) m | ìµœì†Œ ì˜¤ì°¨: {error_mm:.4f} mm")
        
        
        accept_offset_list.append(pos_mm)
        accept_error_list.append(error_mm)


    print("\nâœ… íƒìƒ‰ ì™„ë£Œ!")
    
    return prove_centers, accept_offset_list, accept_error_list

def live_aruco_detection():
    global centers_list, x_axes_list, y_axes_list, z_axes_list
    global isCollect
    global accept_data_list
    global init_offset
    # ZED ì¹´ë©”ë¼ ê°ì²´ ìƒì„± ë° ì´ˆê¸°í™”
    zed = sl.Camera()
    input_type = sl.InputType()
    init = sl.InitParameters(input_t=input_type)
    init.camera_resolution = sl.RESOLUTION.HD1200
    init.coordinate_system = sl.COORDINATE_SYSTEM.RIGHT_HANDED_Y_UP
    init.depth_mode = sl.DEPTH_MODE.ULTRA
    init.coordinate_units = sl.UNIT.MILLIMETER

    err = zed.open(init)
    if err != sl.ERROR_CODE.SUCCESS:
        print("ZED ì—´ê¸° ì‹¤íŒ¨:", repr(err))
        zed.close()
        exit(1)

    # ZEDì—ì„œ ì¹´ë©”ë¼ ë³´ì • íŒŒë¼ë¯¸í„° ì–»ê¸°
    calibration_params = zed.get_camera_information().camera_configuration.calibration_parameters
    
    
    stereo_transform = calibration_params.stereo_transform

    intrinsics_L = calibration_params.left_cam  
    intrinsics_R = calibration_params.right_cam

    # Stero Camera ì„¤ì •
    # íˆ¬ì˜ í–‰ë ¬ ê³„ì‚°
    camera_matrix_L = np.array([
        [intrinsics_L.fx, 0, intrinsics_L.cx],
        [0, intrinsics_L.fy, intrinsics_L.cy],
        [0, 0, 1]
    ])

    camera_matrix_R = np.array([
        [intrinsics_R.fx, 0, intrinsics_R.cx],
        [0, intrinsics_R.fy, intrinsics_R.cy],
        [0, 0, 1]
    ])
    rot = stereo_transform.get_rotation_matrix()  # 3x3 numpy array
    trans = stereo_transform.get_translation()    # sl.Translation (x, y, z)
    R = np.array(rot.r).reshape((3,3))
    T = np.array(trans.get()).reshape((3, 1))
    P1 = camera_matrix_L @ np.hstack((np.eye(3), np.zeros((3, 1))))
    P2 = camera_matrix_R @ np.hstack((R, T))

    # ArUco ë§ˆì»¤ íƒì§€ê¸° ì„¤ì •
    aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_5X5_50)
    aruco_params = cv2.aruco.DetectorParameters()
    detector = cv2.aruco.ArucoDetector(aruco_dict, aruco_params)
    marker_size = 0.04  # ë§ˆì»¤ í¬ê¸° (ë‹¨ìœ„: meter)

    left_image = sl.Mat()
    right_image = sl.Mat()

    runtime_parameters = sl.RuntimeParameters()
    time.sleep(1)

    while True:
        if zed.grab(runtime_parameters) == sl.ERROR_CODE.SUCCESS:
            zed.retrieve_image(left_image, sl.VIEW.LEFT)
            zed.retrieve_image(right_image, sl.VIEW.RIGHT)

            left_np = left_image.get_data()
            right_np = right_image.get_data()

            # ê·¸ë ˆì´ ë³€í™˜
            gray_left = cv2.cvtColor(left_np, cv2.COLOR_BGRA2GRAY)
            gray_right = cv2.cvtColor(right_np, cv2.COLOR_BGRA2GRAY)

            # ArUco ë§ˆì»¤ ê²€ì¶œ
            detector = cv2.aruco.ArucoDetector(aruco_dict, aruco_params)
            corners_l, ids_l, _ = detector.detectMarkers(gray_left)
            corners_r, ids_r, _ = detector.detectMarkers(gray_right)
            
            criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)
            win_size = (5, 5)
            zero_zone = (-1, -1)

            # ìˆ˜ì§‘ ì‹œì‘
            if cv2.waitKey(1) & 0xFF == ord('c'):
                isCollect = True
                print(f"isCollect: {isCollect}")
            # ìˆ˜ì§‘ ì¢…ë£Œ
            if cv2.waitKey(1) & 0xFF == ord('v'):
                isCollect = False
                print(f"isCollect: {isCollect}")

            if ids_l is not None and ids_r is not None:
                for i, id_l in enumerate(ids_l):
                    if id_l in ids_r:
                        idx_r = np.where(ids_r == id_l)[0][0]
                        
                        #ì™œê³¡
                        #undistorted_pts_l = cv2.undistortPoints(corners_l, camera_matrix_L, intrinsics_L.disto)
                        #undistorted_pts_r = cv2.undistortPoints(corners_r, camera_matrix_R, intrinsics_R.disto)

                        # ë§ˆì»¤ ì¤‘ì‹¬ ì¢Œí‘œ ê³„ì‚° (í”½ì…€ ë‹¨ìœ„)
                        corner_l = corners_l[i][0]
                        corner_r = corners_r[idx_r][0]

                        cv2.cornerSubPix(gray_left, corner_l, win_size, zero_zone, criteria)
                        cv2.cornerSubPix(gray_right, corner_r, win_size, zero_zone, criteria)


                        center_l = np.mean(corner_l, axis=0).reshape(2, 1)
                        center_r = np.mean(corner_r, axis=0).reshape(2, 1)

                        # ì‚¼ê°ì¸¡ëŸ‰ì„ í†µí•œ 3D ìœ„ì¹˜ ê³„ì‚°
                        points_4d_hom = cv2.triangulatePoints(P1, P2, center_l, center_r)
                        points_3d = (points_4d_hom / points_4d_hom[3])[:3]  # ì •ê·œí™”
                        points_3d_cv = points_3d.copy()
                        points_3d_cv[1] = -points_3d_cv[1]

                        corner3d_pts = np.zeros((4, 3))

                        # íšŒì „ í–‰ë ¬ ìƒì„±
                        for j in range(4):
                            pt_l = corner_l[j].reshape(2, 1)
                            pt_r = corner_r[j].reshape(2, 1)

                            pt_4d = cv2.triangulatePoints(P1, P2, pt_l, pt_r)
                            pt_3d = (pt_4d / pt_4d[3])[:3].ravel()  # â† ì´ê²Œ ì¤‘ìš”í•¨
                            pt_3d_cv = pt_3d.copy()
                            pt_3d_cv[1] = -pt_3d_cv[1]

                            corner3d_pts[j] = pt_3d_cv  # ì •ê·œí™”ëœ 3D ì¢Œí‘œ ì €ì¥

                        R, t = compute_pose_from_corners(corner3d_pts)

                        # ì˜¤ì¼ëŸ¬ ê°
                        roll, pitch, yaw = rotationMatrixToEulerAngles(R)
                        # ------Get Pointcloud Data------
                        
                        #point_cloud = sl.Mat()
                        #zed.retrieve_measure(point_cloud, sl.MEASURE.XYZBGRA)

                        # ... ë§ˆì»¤ ì½”ë„ˆì˜ 2D ì¢Œí‘œ corner_l (u, v)ë¥¼ ì–»ì€ í›„ ...
                        #corner3d_pts_2 = np.zeros((4, 3))
                        #passCount = 0
                        # ê° ì½”ë„ˆì˜ 3D ì¢Œí‘œë¥¼ SDKì—ì„œ ì§ì ‘ ì¡°íšŒí•©ë‹ˆë‹¤.
                        #for j in range(4):
                        #    u = int(corner_l[j][0])
                        #    v = int(corner_l[j][1])
                        #    err, point_3d = point_cloud.get_value(u, v)
                        #    x_3d, y_3d, z_3d = point_3d[0], point_3d[1], point_3d[2]
                        #    corner3d_pts_2[j] = [x_3d, y_3d, z_3d]
                        #    #if err == sl.ERROR_CODE.SUCCESS and math.isfinite(point_3d[2]):
                        #    #    # isfinite ì²´í¬ë¡œ ìœ íš¨í•œ ê¹Šì´ ê°’ì¸ì§€ í™•ì¸
                        #    #    x_3d, y_3d, z_3d = point_3d[0], point_3d[1], point_3d[2]
                        #    #    corner3d_pts_2[j] = [x_3d, y_3d, z_3d]
                        #    #    passCount += 1
                        #    #else:
                        #    #    # ìœ íš¨í•˜ì§€ ì•Šì€ ê°’ì´ë©´ ì´ ì¸¡ì •ì€ ê±´ë„ˆë›°ëŠ” ë¡œì§ ì¶”ê°€
                        #    #    pass 
                        #center = np.zeros(3)
                        #if passCount > 3:
                        #center = np.mean(corner3d_pts_2, axis=0)
                        #print(f"ğŸ¯ ID {int(id_l)} ìœ„ì¹˜ (pc)(mm): {center}")
                        #R_2, t_2 = compute_pose_from_corners(corner3d_pts)

                        # ------Get Pointcloud Data------

                        #print(f"ğŸ¯ ID {int(id_l)} ìœ„ì¹˜ (raw)(mm): {points_3d.ravel()}")

                        print(f"ğŸ¯ ID {int(id_l)} ìœ„ì¹˜ (cv)(mm): {points_3d_cv.ravel()}")
                        print(f"ğŸ¯ ID {int(id_l)} íšŒì „ ê°’ (cv)(ë„): {roll * 180/math.pi}, {pitch* 180/math.pi}, {yaw* 180/math.pi}")
                        
                        if int(id_l) == 10:
                            offset = init_offset * 1000
                            probe_center = points_3d_cv.ravel()
                            #axes = np.ndarray(R[:, 0], R[:, 1], R[:, 2])
                            probe_tip_pos = get_probe_tip_pos(offset, probe_center, R) 
                            print(f"probe_centerpos: {probe_center} \n probe_tip_pos: {probe_tip_pos}")
                            # 3. cv2.projectPoints()ë¥¼ ìœ„í•œ ì…ë ¥ê°’ ì¤€ë¹„
                            # ZEDì˜ 3D ì¢Œí‘œëŠ” ì´ë¯¸ ì™¼ìª½ ì¹´ë©”ë¼ ê¸°ì¤€ì´ë¯€ë¡œ rvec, tvecì€ 0ìœ¼ë¡œ ì„¤ì •
                            rvec = np.zeros((3, 1))
                            tvec = np.zeros((3, 1))

                            # íˆ¬ì˜í•  3D í¬ì¸íŠ¸ë¥¼ ì˜¬ë°”ë¥¸ shapeìœ¼ë¡œ ë³€í™˜: (1, 1, 3)
                            point_3d_to_project = probe_tip_pos.reshape(1, 1, 3)

                            # 4. 3D ì¢Œí‘œë¥¼ 2D í”½ì…€ ì¢Œí‘œë¡œ íˆ¬ì˜
                            # camera_matrix_Lì™€ intrinsics_L.distoëŠ” ë¯¸ë¦¬ ê³„ì‚°ë˜ì–´ ìˆì–´ì•¼ í•¨
                            point_2d_projected, _ = cv2.projectPoints(point_3d_to_project, rvec, tvec, camera_matrix_L, intrinsics_L.disto)

                            # 5. íˆ¬ì˜ëœ 2D ì¢Œí‘œë¥¼ í™”ë©´ì— ê·¸ë¦¬ê¸°
                            if point_2d_projected is not None:
                                # pt_2dì˜ shapeì€ (1, 1, 2)ì´ë¯€ë¡œ, ì •ìˆ˜í˜• (x, y) íŠœí”Œë¡œ ë³€í™˜
                                pt_2d = tuple(point_2d_projected.ravel().astype(int))

                                # ì™¼ìª½ ì¹´ë©”ë¼ ë·°(left_np)ì— ì‹­ì(+) ëª¨ì–‘ìœ¼ë¡œ ê·¸ë¦¬ê¸°
                                cv2.drawMarker(left_np, pt_2d, color=(0, 0, 255), markerType=cv2.MARKER_CROSS, 
                                               markerSize=20, thickness=2)
                        if isCollect: 
                            print(f"[ADD!] center: {points_3d_cv.ravel()} \n x_axes: {R[:, 0]} \n y_axes: {R[:, 1]} \n z_axes: {R[:, 2]}")
                            centers_list.append(points_3d_cv.ravel()/1000)
                            x_axes_list.append(R[:, 0])
                            y_axes_list.append(R[:, 1]) 
                            z_axes_list.append(R[:, 2])
                        
                        if len(centers_list) > 9:
                            # ì´ ì½”ë“œë„ ì „ì—­ ë¦¬ìŠ¤íŠ¸ë¥¼ ì˜¬ë°”ë¥´ê²Œ ì°¸ì¡°í•©ë‹ˆë‹¤.
                            prove_centers = np.array(centers_list)
                            x_axes = np.array(x_axes_list)
                            y_axes = np.array(y_axes_list)
                            z_axes = np.array(z_axes_list)
                            # â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼ ì—¬ê¸°ì— ì¶”ê°€ â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼
                            print("\n" + "="*25 + " ë°ì´í„° í™•ì¸ " + "="*25)
                            num_points = len(prove_centers)
                            for i in range(num_points):
                                # f-stringê³¼ ì„œì‹ ì§€ì •ìë¥¼ ì´ìš©í•´ ê¹”ë”í•˜ê²Œ ì¶œë ¥
                                print(f"[{i+1:02d}] Center=[{prove_centers[i][0]: .4f}, {prove_centers[i][1]: .4f}, {prove_centers[i][2]: .4f}] | "
                                      f"X_Axis=[{x_axes[i][0]: .4f}, {x_axes[i][1]: .4f}, {x_axes[i][2]: .4f}]")
                            print("="*62 + "\n")
                            # â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–² ì—¬ê¸°ê¹Œì§€ ì¶”ê°€ â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²
                            center, cal_offset, errors = calculate_optimal_offset(prove_centers, x_axes, y_axes, z_axes)
                            error_avg = 0.0
                            for error in errors:
                                error_avg += error
                            error_avg /= 10
                            if error_avg < 1.5:
                                accept_data_list.append((center, cal_offset, errors))
                            # ì´ í• ë‹¹ë¬¸ë„ ì´ì œ ì „ì—­ ë¦¬ìŠ¤íŠ¸ë¥¼ ë¹„ìš°ëŠ” ë™ì‘ì„ ì˜¬ë°”ë¥´ê²Œ ìˆ˜í–‰í•©ë‹ˆë‹¤.
                            centers_list = []
                            x_axes_list = []
                            y_axes_list = []
                            z_axes_list = [] 
                        #print(f"ğŸ¯ ID {int(id_l)} íšŒì „ ê°’ : {v1}, {v2}, {v3}")

                        # ì‹œê°í™”
                        cv2.circle(left_np, tuple(center_l.ravel().astype(int)), 5, (0, 255, 0), -1)
                        cv2.circle(right_np, tuple(center_r.ravel().astype(int)), 5, (0, 0, 255), -1)



            # í™”ë©´ ì¶œë ¥
            combined = np.hstack((left_np, right_np))
            resized_img = cv2.resize(combined, (1280, 480))
            cv2.imshow("Left | Right", resized_img)
            # 'q' í‚¤ ëˆ„ë¥´ë©´ ì¢…ë£Œ
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break

        # ì¢…ë£Œ ì²˜ë¦¬
    zed.close()
    cv2.destroyAllWindows()

def check_accept_data():
    global accept_data_list
    print("\n" + "="*25 + " ìµœì¢… í•©ê²© ë°ì´í„° " + "="*25)
    dist = 0.0
    if not accept_data_list:
        print("ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        # enumerateë¥¼ ì‚¬ìš©í•˜ë©´ ì¸ë±ìŠ¤ ë²ˆí˜¸(i)ì™€ í•­ëª©(data)ì„ í•œë²ˆì— ê°€ì ¸ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        for i, data in enumerate(accept_data_list):
            # dataëŠ” (offset, error) í˜•íƒœì˜ íŠœí”Œì…ë‹ˆë‹¤.
            pose = data[0]
            offset = data[1]
            error = data[2]

            # f-string ì„œì‹ì„ ì´ìš©í•´ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥
            print(f"--- ë°ì´í„° [{i+1}/{len(accept_data_list)}] ---")

            # NumPy ë°°ì—´ì„ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥í•˜ê¸° ìœ„í•œ ì„œì‹
            #offset_str = np.array2string(offset, formatter={'float_kind':lambda x: "%.6f" % x})
            for j in range(len(pose)):
                dist += pose[j][2]
                print(f"  center pose: {pose[j]}")
                print(f"  offset: {offset[j]}")
                print(f"  error: {error[j]:.4f} mm")
            dist /= 10
            dist *= 1000
            print(f"--- ë°ì´í„° [{i+1}/{len(accept_data_list)} ê±°ë¦¬: {dist * -1:.1f}mm] ---")
            dist = 0.0

    print("="*64)


def main():
    init()
    print("Starting ArUco marker detection with ZED camera...")
    live_aruco_detection()
    print("End marker detection with ZED camera...")
    check_accept_data()

if __name__ == "__main__":
    main()